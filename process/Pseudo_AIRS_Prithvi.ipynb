{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pseudo-Integration of AIRS Data with Prithvi-100M Model**\n",
    "This file demonstrates a conceptual approach for preparing and evaluating the Atmospheric Infrared Sounder (AIRS) dataset for use with the Prithvi-100M model. The process is divided into several key steps, each represented in pseudo-code, to illustrate the end-to-end workflow of data preparation, model adaptation, and performance testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Replace 'path_to_the_file.h5' with the actual path to your HDF5 file\n",
    "file_path = 'path_to_the_file.h5'\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    print(\"File opened successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all top-level groups and datasets\n",
    "print(\"Top-level groups and datasets:\")\n",
    "for name in file:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 'L1C_AIRS_Science' group\n",
    "airs_science_group = file['L1C_AIRS_Science']\n",
    "    \n",
    "# List datasets within 'L1C_AIRS_Science'\n",
    "print(\"\\nDatasets within 'L1C_AIRS_Science':\")\n",
    "for name in airs_science_group:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for radiance and geolocation datasets specifically\n",
    "print(\"\\nChecking for specific datasets:\")\n",
    "if 'Data Fields/radiances' in airs_science_group:\n",
    "    print(\"Radiance dataset found.\")\n",
    "if 'Geolocation Fields/Latitude' in airs_science_group and 'Geolocation Fields/Longitude' in airs_science_group:\n",
    "    print(\"Geolocation datasets found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inspecting the shape and data type of the radiance dataset\n",
    "radiance_shape = airs_science_group['Data Fields/radiances'].shape\n",
    "radiance_dtype = airs_science_group['Data Fields/radiances'].dtype\n",
    "print(f\"\\nRadiance dataset shape: {radiance_shape}, Data type: {radiance_dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Extract Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract radiance data and ensure it's in little-endian format\n",
    "radiances = file['L1C_AIRS_Science/Data Fields/radiances'][:]\n",
    "radiances = radiances.newbyteorder('<').astype(np.float32)\n",
    "\n",
    "# Replace fill values with NaN for radiances (assuming -9999 is the fill value)\n",
    "fill_value = -9999\n",
    "radiances[radiances == fill_value] = np.nan\n",
    "\n",
    "# Extract geolocation data, ensuring little-endian format and conversion to appropriate data types\n",
    "latitudes = file['L1C_AIRS_Science/Geolocation Fields/Latitude'][:]\n",
    "latitudes = latitudes.newbyteorder('<').astype(np.float64)\n",
    "\n",
    "longitudes = file['L1C_AIRS_Science/Geolocation Fields/Longitude'][:]\n",
    "longitudes = longitudes.newbyteorder('<').astype(np.float64)\n",
    "\n",
    "times = file['L1C_AIRS_Science/Geolocation Fields/Time'][:]\n",
    "times = times.newbyteorder('<').astype(np.float64)\n",
    "\n",
    "# Extract channel wavelengths\n",
    "# Check this in more detail \n",
    "# This step assumes there is a dataset within our HDF5 file that contains the central wavelength for each channel\n",
    "# Adjust 'Path/To/ChannelWavelengths' to the actual path within HDF5 file\n",
    "channel_wavelengths = file['Path/To/ChannelWavelengths'][:]\n",
    "channel_wavelengths = channel_wavelengths.newbyteorder('<').astype(np.float64)\n",
    "\n",
    "# Validate the shapes of the datasets to ensure they align\n",
    "assert radiances.shape[0:2] == latitudes.shape == longitudes.shape, \"Mismatch in spatial dimensions between radiance and geolocation data.\"\n",
    "\n",
    "# Print shapes as a sanity check and confirm extraction\n",
    "print(f\"Radiance Shape: {radiances.shape}, Latitude Shape: {latitudes.shape}, Longitude Shape: {longitudes.shape}\")\n",
    "\n",
    "# Optionally, extract additional metadata for context (example: start and end time)\n",
    "start_time = file['L1C_AIRS_Science/Swath Attributes/start_Time'][0]\n",
    "end_time = file['L1C_AIRS_Science/Swath Attributes/end_Time'][0]\n",
    "print(f\"Start Time: {start_time}, End Time: {end_time}\")\n",
    "\n",
    "# Print a brief overview of the channel wavelengths to confirm successful extraction\n",
    "print(f\"Extracted channel wavelengths: {channel_wavelengths[:10]}\")  # Print first 10 wavelengths as a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudo-code to illustrate the preprocessing steps\n",
    "import numpy as np\n",
    "\n",
    "# Example wavelength ranges for NIR, SWIR1, and SWIR2 bands in micrometers (Âµm)\n",
    "nir_wavelength_range = (0.85, 0.88)\n",
    "swir1_wavelength_range = (1.57, 1.65)\n",
    "swir2_wavelength_range = (2.11, 2.29)\n",
    "\n",
    "# Function to find channel indexes based on wavelength range\n",
    "def find_channel_indexes(wavelength_range, channel_wavelengths):\n",
    "    indexes = np.where((channel_wavelengths >= wavelength_range[0]) & \n",
    "                       (channel_wavelengths <= wavelength_range[1]))[0]\n",
    "    return indexes\n",
    "\n",
    "# Find indexes for NIR, SWIR1, and SWIR2 bands\n",
    "nir_channel_index = find_channel_indexes(nir_wavelength_range, channel_wavelengths)\n",
    "swir1_channel_index = find_channel_indexes(swir1_wavelength_range, channel_wavelengths)\n",
    "swir2_channel_index = find_channel_indexes(swir2_wavelength_range, channel_wavelengths)\n",
    "\n",
    "# Ensure radiance data is in the desired floating-point precision\n",
    "radiances = radiances.astype(np.float32)\n",
    "\n",
    "# Normalize radiance data\n",
    "radiances_normalized = (radiances - np.nanmin(radiances, axis=(0, 1), keepdims=True)) / \\\n",
    "                       (np.nanmax(radiances, axis=(0, 1), keepdims=True) - np.nanmin(radiances, axis=(0, 1), keepdims=True))\n",
    "\n",
    "# Selecting channels based on identified indexes\n",
    "nir_radiances = radiances_normalized[:, :, nir_channel_index]\n",
    "swir1_radiances = radiances_normalized[:, :, swir1_channel_index]\n",
    "swir2_radiances = radiances_normalized[:, :, swir2_channel_index]\n",
    "\n",
    "# Handling NaN values\n",
    "nir_radiances = np.nan_to_num(nir_radiances, nan=-9999)\n",
    "swir1_radiances = np.nan_to_num(swir1_radiances, nan=-9999)\n",
    "swir2_radiances = np.nan_to_num(swir2_radiances, nan=-9999)\n",
    "\n",
    "# Example calculation using NIR and SWIR1 (this is an illustrative example, adjust as needed)\n",
    "ndvi_like_index = (nir_radiances - swir1_radiances) / (nir_radiances + swir1_radiances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "# Assuming 'latitudes', 'longitudes', 'times', 'nir_radiances', 'swir1_radiances', and 'swir2_radiances' are numpy arrays\n",
    "\n",
    "# Convert the multi-dimensional arrays to 1D arrays for easier manipulation\n",
    "latitudes_flat = latitudes.flatten()\n",
    "longitudes_flat = longitudes.flatten()\n",
    "times_flat = times.flatten()\n",
    "nir_radiances_flat = nir_radiances.flatten()\n",
    "swir1_radiances_flat = swir1_radiances.flatten()\n",
    "swir2_radiances_flat = swir2_radiances.flatten()\n",
    "\n",
    "# Create a DataFrame from the 1D arrays\n",
    "structured_data = pd.DataFrame({\n",
    "    'Latitude': latitudes_flat,\n",
    "    'Longitude': longitudes_flat,\n",
    "    'Time': times_flat,\n",
    "    'NIR': nir_radiances_flat,\n",
    "    'SWIR1': swir1_radiances_flat,\n",
    "    'SWIR2': swir2_radiances_flat\n",
    "})\n",
    "\n",
    "# Assuming we want to align with a specific spatial resolution, e.g., 0.05 degrees\n",
    "# This simulates a \"binning\" approach to group data by geographical location\n",
    "resolution = 0.05  # Change this to match the desired spatial resolution\n",
    "structured_data['Lat_bin'] = np.round(structured_data['Latitude'] / resolution) * resolution\n",
    "structured_data['Lon_bin'] = np.round(structured_data['Longitude'] / resolution) * resolution\n",
    "\n",
    "# Aggregate data by the binned latitude and longitude, averaging the values\n",
    "# This approach simplifies handling of spatial data by grouping it into coarser resolution \"bins\"\n",
    "aggregated_data = structured_data.groupby(['Lat_bin', 'Lon_bin']).mean().reset_index()\n",
    "\n",
    "# Note: The choice of resolution (0.05 in this example) should be informed by the model's documentation\n",
    "# and the scale of analysis we aim to perform. Adjust it based on the spatial granularity of the model's training data.\n",
    "\n",
    "# Prepare the aggregated data for model input\n",
    "# The format (e.g., Pandas DataFrame vs. NumPy array) will depend on the model's expected input format\n",
    "# If the model expects a multi-dimensional array format, further processing may be required to reshape the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Model Adaptation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForImageClassification, AutoFeatureExtractor\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "model_name = 'ibm-nasa-geospatial/Prithvi-100M'\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "def prepare_inputs(feature_extractor, aggregated_data, image_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Prepares model inputs from aggregated AIRS data by simulating multispectral imagery.\n",
    "\n",
    "    Parameters:\n",
    "    - feature_extractor: The feature extractor associated with the model.\n",
    "    - aggregated_data: A Pandas DataFrame containing the aggregated AIRS data. Assumes data is already aggregated by spatial binning.\n",
    "    - image_size: A tuple indicating the size (height, width) to which the images will be resized.\n",
    "\n",
    "    Returns:\n",
    "    - inputs: A tensor suitable for model input, including multispectral and temporal dimensions.\n",
    "    \"\"\"\n",
    "    images_list = []\n",
    "\n",
    "    # Assuming aggregated_data includes columns for NIR, SWIR1, and SWIR2 for simplicity\n",
    "    for _, row in aggregated_data.iterrows():\n",
    "        # Simulate an image from the band values; assumes bands are already scaled to [0, 1]\n",
    "        image_data = np.stack([row['NIR'], row['SWIR1'], row['SWIR2']], axis=-1)\n",
    "        image = Image.fromarray((image_data * 255).astype(np.uint8))\n",
    "        image = image.resize(image_size, Image.BILINEAR)\n",
    "        images_list.append(image)\n",
    "\n",
    "    inputs = feature_extractor(images=images_list, return_tensors=\"pt\", padding=True, max_length=512, truncation=True)\n",
    "    \n",
    "    return inputs['pixel_values']\n",
    "\n",
    "def test_model(model, inputs, true_labels):\n",
    "    \"\"\"\n",
    "    Tests the model with the prepared inputs and returns performance metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The loaded model ready for inference.\n",
    "    - inputs: The inputs prepared for the model.\n",
    "    - true_labels: The ground truth labels for the inputs, for evaluating model performance.\n",
    "    \n",
    "    Returns:\n",
    "    - performance: A dictionary containing performance metrics such as accuracy and F1 score.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels.cpu().numpy(), predictions.cpu().numpy())\n",
    "    f1 = f1_score(true_labels.cpu().numpy(), predictions.cpu().numpy(), average='weighted')\n",
    "\n",
    "    performance = {\"accuracy\": accuracy, \"f1_score\": f1}\n",
    "    return performance\n",
    "\n",
    "# Example usage\n",
    "# Note: `true_labels` need to be defined based on our specific task and data\n",
    "adapted_inputs = prepare_inputs(feature_extractor, aggregated_data)\n",
    "performance = test_model(model, adapted_inputs, true_labels)\n",
    "print(f\"Model performance: {performance}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
